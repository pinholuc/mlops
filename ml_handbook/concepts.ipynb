{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXFkfKQyxFQk3+2vu4S5G/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinholuc/mlops/blob/master/ml_handbook/concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "on5TzbSylWir"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import ensemble, preprocessing, tree\n",
        "from sklearn.metrics import auc, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "from yellowbrick.classifier import ConfusionMatrix, ROCAUC\n",
        "from yellowbrick.model_selection import LearningCurve\n",
        "\n",
        "# Read titanic survival data\n",
        "df = pd.read_excel(\"./titanic/titanic3.xls\")\n",
        "\n",
        "# Droping features that are not useful to our model\n",
        "df = df.drop(columns = [\"name\", \n",
        "                        \"ticket\", \n",
        "                        \"home.dest\", \n",
        "                        \"boat\", \n",
        "                        \"body\", \n",
        "                        \"cabin\"])\n",
        "\n",
        "# Getting rid of string/object features\n",
        "df = pd.get_dummies(df).drop(columns=\"sex_male\")\n",
        "\n",
        "# Segregate features (x) and labels (y)\n",
        "X = df.drop(columns=\"survived\")\n",
        "\n",
        "# Labels (y)\n",
        "y = df.survived\n",
        "\n",
        "# Split in train and validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling Missing Data\n",
        "\n",
        "df.age.value_counts(dropna=False)\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn import impute\n",
        "\n",
        "num_cols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"sex_female\"]\n",
        "imputer = impute.IterativeImputer()\n",
        "imputed = imputer.fit_transform(X_train[num_cols])\n",
        "X_train.loc[:, num_cols] = imputed\n",
        "imputed = imputer.transform(X_test[num_cols])\n",
        "X_test.loc[:, num_cols] = imputed"
      ],
      "metadata": {
        "id": "HjiK77zvsxKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing data\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "media igual a zero e desvio padrao igual a 1\n",
        "desse modo, os modelos nao tratarao as variaveis com escalas maiores como\n",
        "mais importante que as variaveis com menor escala\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cols = \"pclass, age, sibsp, fare\".split(\",\")\n",
        "sca = preprocessing.StandardScaler()\n",
        "\n",
        "X_train = sca.fit_transform(X_train)\n",
        "X_train = pd.DataFrame(X_train, columns=cols)\n",
        "X_test = sca.transform(X_test)\n",
        "X_test = pd.DataFrame(X_test, columns=cols)\n"
      ],
      "metadata": {
        "id": "cd-H7xXj5IPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando modelos de base para benchmark\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "bm = DummyClassifier()\n",
        "bm.fit(X_train, y_train)\n",
        "bm.score(X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXW-1eEx8Z_d",
        "outputId": "e9d8fe23-0abe-4437-dd27-37f2354a0b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5699745547073791"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-fold validacao cruzada\n",
        "\n",
        "\"\"\"\n",
        "KFOLD: https://drigols.medium.com/introdu%C3%A7%C3%A3o-a-valida%C3%A7%C3%A3o-cruzada-k-fold-2a6bced32a90\n",
        "Outra observação muito importante é que a Validação-Cruzada: K-Fold não \n",
        "retorma um modelo (Por exemplo, Regressão Linear) pronto para nós utilizarmos.\n",
        " Ele retorna os scores de cada subdivisão, ou seja, \n",
        "quão performático cada uma é.\n",
        "\n",
        "AUC: area under ROC curve. ROC = Receiver operating characteristic\n",
        "https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
        "\n",
        "The ROC curve is created by plotting the true positive rate (TPR) against the \n",
        "false positive rate (FPR) at various threshold settings.\n",
        "The true-positive rate is also known as sensitivity, recall or\n",
        "probability of detection\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "X = pd.concat([X_train, X_test])\n",
        "y = pd.concat([y_train, y_test])\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost\n",
        "\n",
        "\n",
        "for model in [\n",
        "    DummyClassifier,\n",
        "    DecisionTreeClassifier,\n",
        "    KNeighborsClassifier,\n",
        "    GaussianNB,\n",
        "    SVC,\n",
        "    RandomForestClassifier,\n",
        "    xgboost.XGBClassifier\n",
        "]:\n",
        "\n",
        "  cls = model()\n",
        "  kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "  s = model_selection.cross_val_score(cls, X, y, scoring=\"roc_auc\", cv=kfold)\n",
        "\n",
        "  print(f\"{model.__name__} AUC: {s.mean()}, STD: {s.std()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKcHHg639Obg",
        "outputId": "a1191859-3e20-4e33-8bc0-dd8f669bdd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier AUC: 0.5, STD: 0.0\n",
            "DecisionTreeClassifier AUC: 0.7547693750229326, STD: 0.02317072542938455\n",
            "KNeighborsClassifier AUC: 0.7187329287747022, STD: 0.040277951013247305\n",
            "GaussianNB AUC: 0.8042960782658678, STD: 0.04438480209202408\n",
            "SVC AUC: 0.7412092038442221, STD: 0.057045949345137584\n",
            "RandomForestClassifier AUC: 0.8474062722238699, STD: 0.02103449935511667\n",
            "XGBClassifier AUC: 0.862312412857627, STD: 0.026543685197120637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um modelo RandomForest\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Uma boa vantagem dos modelos baseados em arvore eh que voce pode inspecionar\n",
        "a importancia dos atributos. A importancia dos atributos nos diz quanto\n",
        "um atributo contribui para o modelo. Observe que remover um atributo nao\n",
        "significa que a pontuacao caira na mesma medida, pois outros atributos \n",
        "poderao ser colineares.\n",
        "\n",
        "A importancia dos atributos eh calculada observando o aumento no erro.\n",
        "Se a remocao de um atributo causar um aumento no erro do modelo, eh sinal\n",
        "de que o atributo eh importante.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf.score(X_test, y_test)\n",
        "metrics.precision_score(y_test, rf.predict(X_test))\n",
        "\n",
        "for col, val in sorted(zip(X_train.columns, rf.feature_importances_),\n",
        "                       key=lambda x: x[1],\n",
        "                       reverse=True)[:5]:\n",
        "  print(f\"{col:10}{val:10.3f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeVXCjVx_eKM",
        "outputId": "495066d9-6e46-4d57-a57d-507db4af98a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age            0.281\n",
            "fare           0.263\n",
            "sex_female     0.241\n",
            "pclass         0.090\n",
            "sibsp          0.049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Otimizando hiperparametros\n",
        "\n",
        "\"\"\"\n",
        "O sklearn tem uma classe de busca em grade (grid search) para avaliar\n",
        "um modelo com diferentes combinacoes de parametros, devolvendo o melhor\n",
        "resultado\n",
        "\"\"\" \n",
        "\n",
        "rf4 = ensemble.RandomForestClassifier()\n",
        "params = {\n",
        "    \"max_features\": [0.4, \"auto\"],\n",
        "    \"n_estimators\": [15, 200],\n",
        "    \"min_samples_leaf\": [1, 0.1],\n",
        "    \"random_state\": [42]\n",
        "}\n",
        "\n",
        "cv = model_selection.GridSearchCV(rf4, params, n_jobs=1).fit(X_train, y_train)\n",
        "print(cv.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38NyjsgRFKBa",
        "outputId": "b888fcd6-13b2-4413-c153-e312f7a34ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_features': 0.4, 'min_samples_leaf': 1, 'n_estimators': 200, 'random_state': 42}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "\"\"\"\n",
        "Nos permite ver as classificacoes corretas, bem como os falso-positivos e\n",
        "os falsos negativos\n",
        "\"\"\"\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = rf.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred)\n",
        "\n",
        "mapping = {0: \"died\", 1: \"survived\"}\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "cm_viz = ConfusionMatrix(rf, classes=[\"died\", \"survived\"], label_encoder=mapping)\n",
        "cm_viz.score(X_test, y_test)\n",
        "cm_viz.poof()\n",
        "fig.savefig(\"mlpr_0304.png\", dpi=300, bbox_inches=\"tight\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qEVQjQaHK81",
        "outputId": "d4364ea3-dd7a-4e96-e75a-d00b4cac574d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/yellowbrick/classifier/base.py:232: YellowbrickWarning: could not determine class_counts_ from previously fitted classifier\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Curva ROC\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Um grafico ROC (Receiver Operating Characteristic) eh uma ferramenta comum usada\n",
        "para avaliar classificadores. Ao calcular a area sob a curva ROC (AUC), podemos \n",
        "obter uma metrica para compara diferentes classificadores.\n",
        "\n",
        "Mostra a taxa dos realmente positivos em relacao a taxa dos falso-positivos.\n",
        "Em geral, quanto mais saliente, melhor. Calcular o AUC fornece um unico numero\n",
        "a ser avaliado. Um valor mais proximo de um eh melhor. Abaixo de 0,5 o modelo\n",
        "eh considerado ruim\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "roc_auc_score(y_test, y_pred)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "roc_viz = ROCAUC(rf)\n",
        "roc_viz.poof()\n",
        "fig.savefig(\"roc.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBZvjQ5RI5Ox",
        "outputId": "656cf54e-322b-4562-ea06-7cddb3a9d2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/yellowbrick/base.py:236: YellowbrickWarning: ROCAUC does not have a reference to a matplotlib.Axes the figure may not render as expected!\n",
            "  warnings.warn(\n",
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Curve\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Uma curva de aprendizado eh usada para nos dizer se temos dados de treinamento\n",
        "suficientes. O modelo eh treinado com porcoes cada vez maiores dos dados e a\n",
        "pontuacao eh calculada.\n",
        "\n",
        "Se a pontuacao da validacao cruzada continuar subindo, talvez seka\n",
        "necessario investir em coletas de mais dados.\n",
        "\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "cv = StratifiedKFold(12)\n",
        "sizes = np.linspace(0.3, 1.0, 10)\n",
        "lc_viz = LearningCurve(rf,\n",
        "                       cv=cv,\n",
        "                       train_sizes=sizes,\n",
        "                       scoring=\"f1_weighted\",\n",
        "                       n_jobs=4,\n",
        "                       ax=ax)\n",
        "lc_viz.fit(X, y)\n",
        "lc_viz.poof()\n",
        "fig.savefig(\"learning_curve.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fifv_NA3NEnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implantando um modelo\n",
        "\n",
        "\"\"\"\n",
        "Ao usar o modulo pickle do Python, podemos fazer a persistencia dos modelos\n",
        "e carrega-los. Depois que tivermos um modelo, chamamos o metodo .predict para\n",
        "obter uma classificacao ou um resultado de uma regressao.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pickle\n",
        "pic = pickle.dumps(rf)\n",
        "model = pickle.loads(pic)\n",
        "y_pred = model.predict(X_test)\n",
        "roc_auc_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdo_XePFN6xW",
        "outputId": "540d7237-522a-46f4-a8ab-e0cca4fbe268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7814217032967034"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}